{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33bcf38f-4e2e-4371-b189-e12efbbb770c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Import necessary libraries\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f220322-fa26-4ea4-b3af-f5733f27aadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data set\n",
    "df = pd.read_csv(\"/Users/macbook/Desktop/internship/data/Diabetes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712db638-3cb1-4858-a838-acacab1a1359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display dataset info\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nFirst 5 Rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3da25f-678f-40b1-8849-8624e20960ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Handle missing values by dropping rows\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b311e9-65ba-4b23-893f-aee14aa8790c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check column names\n",
    "print(\"\\nColumn Names:\")\n",
    "print(df.columns)\n",
    "\n",
    "# Preprocessing\n",
    "# Identify categorical and numerical columns\n",
    "categorical_cols = ['Gender', 'Blood Pressure', 'Family History of Diabetes', 'Smoking', 'Diet', 'Exercise']\n",
    "numerical_cols = ['Age', 'BMI', 'FBS', 'HbA1c']\n",
    "\n",
    "# Target column\n",
    "target_column = 'Diagnosis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b64dea-f8ea-41cd-a807-03132cab3b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ColumnTransformer to preprocess the data in the columns\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef0778a-e81b-4fff-b4d8-a003898378b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split features and target\n",
    "X = df.drop(target_column, axis=1)\n",
    "y = df[target_column]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cecc2fc-9bae-424f-a65a-e0947e092137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing\n",
    "X_train_scaled = preprocessor.fit_transform(X_train)\n",
    "X_test_scaled = preprocessor.transform(X_test)\n",
    "\n",
    "# Convert y_train and y_test to binary (label encoding)\n",
    "y_train = y_train.map({'No': 0, 'Yes': 1}).values\n",
    "y_test = y_test.map({'No': 0, 'Yes': 1}).values\n",
    "\n",
    "# Convert X_train_scaled and X_test_scaled to NumPy arrays (Tensorflow does not accept pandas dataframe as input, it accepts either Tensorflow tensors or NumPy arrays)\n",
    "X_train_scaled = X_train_scaled.astype('float32')\n",
    "X_test_scaled = X_test_scaled.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae799018-b57e-49d7-8498-41d2b1e9a4cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8aff5eb-4d92-4642-9b83-6f29627cf98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout,Input\n",
    "\n",
    "#suppress warnings\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "# Build the TensorFlow MLP model\n",
    "tf_model = Sequential([\n",
    "    Input(shape=(X_train_scaled.shape[1],)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6a69f9-5003-4255-81ce-ccece6958df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "tf_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = tf_model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b5988b-8957-44e4-b0d5-fccd52c23991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "y_pred_tf = (tf_model.predict(X_test_scaled) > 0.3).astype(int)\n",
    "print(\"\\nTensorFlow MLP Performance:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_tf))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_tf))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6820bf-d57d-4c44-8dc6-e46e7c62849f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss (TensorFlow)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c90a83-08e0-4595-8c35-7e4fc7e4c8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.Series(y_train).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd246dcc-d8a9-4c1b-a8fd-540fcac8e9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#handle imbalance\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# Compute balanced class weights\n",
    "class_weights = dict(enumerate(class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")))\n",
    "print(\"Class Weights:\", class_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a7d047-56c7-4b8a-816d-f772fffa0c04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d429af01-dbf2-4637-8c50-595f25ba13dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#baseline model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "#suppress warnings\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "# Baseline model\n",
    "tf_model1 = Sequential([\n",
    "    Input(shape=(X_train_scaled.shape[1],)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "tf_model1.compile(\n",
    "    optimizer=Adam(learning_rate=0.0005),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history1 = tf_model1.fit(\n",
    "    X_train_scaled, y_train, \n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    class_weight=class_weights,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2fcc0a-290c-45f1-9a7f-acefb5a4cd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "y_pred_prob = tf_model1.predict(X_test_scaled)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred, labels=[0,1]))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9063de16-9d39-4ca7-917e-a729d5d5ef47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Example: Step 2 — adjust dropout and learning rate\n",
    "tf_model2 = Sequential([\n",
    "    Input(shape=(X_train_scaled.shape[1],)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.2),   # reduced dropout\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.1),   # reduced dropout\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "tf_model2.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),  # slightly higher learning rate\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train using class weights\n",
    "history2 = tf_model2.fit(\n",
    "    X_train_scaled, y_train,   # original data\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    class_weight=class_weights,   # <-- balanced training\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7102d5c-69f6-4962-9bc3-beb9f1131cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "y_pred_prob = tf_model2.predict(X_test_scaled)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred, labels=[0,1]))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dff65d-b725-48cb-b111-2d3488b7a113",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.unique(y_test, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0db88e-6877-4cb1-a6eb-b32478722204",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "tf_model3 = Sequential([\n",
    "    Input(shape=(X_train_scaled.shape[1],)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),   # reduced dropout\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),   # reduced dropout\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "tf_model3.compile(\n",
    "    optimizer=Adam(learning_rate=0.0005),  \n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "# Add early stopping\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,              # stop if val_loss doesn’t improve for 10 epochs\n",
    "    restore_best_weights=True\n",
    ")    \n",
    "# Train using class weights\n",
    "history3 = tf_model3.fit(\n",
    "    X_train_scaled, y_train, \n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stop],\n",
    "    class_weight=class_weights,   # <-- balanced training\n",
    "    verbose=1\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc3b6b1-ca1f-4f23-b37d-22121304d210",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = tf_model3.predict(X_test_scaled)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred, labels=[0,1]))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb75881-d980-4f8b-89ed-766c5b240aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model4 = Sequential([\n",
    "    Input(shape=(X_train_scaled.shape[1],)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "tf_model4.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=6,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history4 = tf_model4.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a2a664-7ff2-448f-bd5e-529e1eb39b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = tf_model4.predict(X_test_scaled)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred, labels=[0,1]))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e295beb-d1a0-4730-b002-ab5b4e53c83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ptimal balance between accuracy and generalisation. It avoided overfitting seen in Model 2 while improving class 1 recall \n",
    "#compared to Model 3. With 94 % overall accuracy and perfect recall for the minority class, Model 4 represents the best \n",
    "#fine-tuned configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10a22b8-3d85-4aa1-8bcd-864fb2d23e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "\n",
    "# --- 1. Predictions ---\n",
    "y_pred_prob = tf_model4.predict(X_test_scaled)       # probabilities\n",
    "y_pred = (y_pred_prob > 0.5).astype(int).flatten()   # binary predictions\n",
    "\n",
    "# --- 2. Classification Report ---\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# --- 3. Confusion Matrix ---\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[0,1], yticklabels=[0,1])\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()\n",
    "\n",
    "# --- 4. ROC Curve & AUC ---\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label='ROC curve (AUC = %0.2f)' % roc_auc)\n",
    "plt.plot([0,1], [0,1], color='gray', lw=1, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "# --- 5. Precision-Recall Curve & Average Precision ---\n",
    "precision, recall, thresholds_pr = precision_recall_curve(y_test, y_pred_prob)\n",
    "avg_precision = average_precision_score(y_test, y_pred_prob)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(recall, precision, color='green', lw=2, label='PR curve (AP = %0.2f)' % avg_precision)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc='lower left')\n",
    "plt.show()\n",
    "\n",
    "# --- 6. Training & Validation Loss/Accuracy Plots ---\n",
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "# Accuracy plot\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history4.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history4.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training & Validation Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Loss plot\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history4.history['loss'], label='Train Loss')\n",
    "plt.plot(history4.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training & Validation Loss')\n",
    "plt.lege\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b82ddc-a4de-44e8-8fe0-980c82413541",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c04db2-89c7-4431-9715-19ec86bb3cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert the Pandas Dataframe data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dcdef9e-06ef-456c-ae84-4e886480dbd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/Users/macbook/.pyenv/versions/3.10.13/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/Users/macbook/.pyenv/versions/3.10.13/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/macbook/pytorch_env/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/macbook/pytorch_env/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/macbook/pytorch_env/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/macbook/pytorch_env/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/macbook/.pyenv/versions/3.10.13/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/macbook/.pyenv/versions/3.10.13/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/macbook/.pyenv/versions/3.10.13/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/macbook/pytorch_env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 519, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/macbook/pytorch_env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 508, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/macbook/pytorch_env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 400, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/macbook/pytorch_env/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 368, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/macbook/pytorch_env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/macbook/pytorch_env/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 455, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/macbook/pytorch_env/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 577, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/macbook/pytorch_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3077, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/macbook/pytorch_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3132, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/macbook/pytorch_env/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/macbook/pytorch_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3336, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/macbook/pytorch_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3519, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/macbook/pytorch_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/qp/jnj6wwv54lv_p5tg2lly4ng00000gn/T/ipykernel_66729/4145893401.py\", line 2, in <module>\n",
      "    import torch.nn as nn\n",
      "  File \"/Users/macbook/pytorch_env/lib/python3.10/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/macbook/pytorch_env/lib/python3.10/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/macbook/pytorch_env/lib/python3.10/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/macbook/pytorch_env/lib/python3.10/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/macbook/pytorch_env/lib/python3.10/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/macbook/pytorch_env/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "source": [
    "# Build the PyTorch MLP model\n",
    "import torch.nn as nn\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.sigmoid(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "819b6b3e-d2c4-4393-aadf-f33336828592",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Initialize the model, loss function, and optimizer\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m input_size \u001b[38;5;241m=\u001b[39m \u001b[43mX_train_scaled\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      3\u001b[0m torch_model \u001b[38;5;241m=\u001b[39m MLP(input_size)\n\u001b[1;32m      4\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mBCELoss()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "input_size = X_train_scaled.shape[1]\n",
    "torch_model = MLP(input_size)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(torch_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d110e88-041c-4d22-9f1a-a661c30f93c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (PyTorch)",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
